{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bc70177",
   "metadata": {},
   "source": [
    "Email spam, are also called as junk emails, are unsolicited messages sent in bulk by email (spamming).\n",
    "\n",
    "In this Data Science Project I will show you how to detect email spam using Machine Learning technique called Natural Language Processing and Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abce8966",
   "metadata": {},
   "source": [
    "### So this program will detect if an email is spam (1) or not (0)\n",
    "Import the libraries :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72061ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b4ed05",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4d39224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0  Subject: naturally irresistible your corporate...     1\n",
       "1  Subject: the stock trading gunslinger  fanny i...     1\n",
       "2  Subject: unbelievable new homes made easy  im ...     1\n",
       "3  Subject: 4 color printing special  request add...     1\n",
       "4  Subject: do not have money , get software cds ...     1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\SHREE\\Downloads\\Python CODES\\Email spam Detection with NLP\\emails.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e16670",
   "metadata": {},
   "source": [
    "Now let’s explore the data and get the number of rows & columns :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aff577c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5728, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e517a99",
   "metadata": {},
   "source": [
    "To get the column names in the data set :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d96c080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'spam'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad0f4c",
   "metadata": {},
   "source": [
    "To check for duplicates and remove them :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c15f8eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5695, 2)\n"
     ]
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343f33c4",
   "metadata": {},
   "source": [
    "To see the number of missing data for each column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84380d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text    0\n",
      "spam    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a6bf48",
   "metadata": {},
   "source": [
    "Now Create a function to clean the text and return the tokens. The cleaning of the text can be done by first removing punctuation and then removing the useless words also known as stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aed7a21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Subject, naturally, irresistible, corporate, ...\n",
       "1    [Subject, stock, trading, gunslinger, fanny, m...\n",
       "2    [Subject, unbelievable, new, homes, made, easy...\n",
       "3    [Subject, 4, color, printing, special, request...\n",
       "4    [Subject, money, get, software, cds, software,...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process(text):\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "\n",
    "    clean = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
    "    return clean\n",
    "# to show the tokenization\n",
    "df['text'].head().apply(process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c942b9",
   "metadata": {},
   "source": [
    "Now convert the text into a matrix of token counts :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f1f844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "message = CountVectorizer(analyzer=process).fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21234f5",
   "metadata": {},
   "source": [
    "Now we need to split the data into training and testing sets, and then we will use this one row of data for testing to make our prediction later on and test to see if the prediction matches with the actual value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "813feaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5695, 37229)\n"
     ]
    }
   ],
   "source": [
    "#split the data into 80% training and 20% testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(message, df['spam'], test_size=0.20, random_state=0)\n",
    "# To see the shape of the data\n",
    "print(message.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad2631c",
   "metadata": {},
   "source": [
    "Now we need to create and train the Multinomial Naive Bayes classifier which is suitable for classification with discrete features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17e66fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and train the Naive Bayes Classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB().fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f3e6f6",
   "metadata": {},
   "source": [
    "To see the classifiers prediction and actual values on the data set :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "488ddbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(classifier.predict(xtrain))\n",
    "print(ytrain.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efd2f7b",
   "metadata": {},
   "source": [
    "Now let’s see how well our model performed by evaluating the Naive Bayes classifier and the report, confusion matrix & accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b72fa67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3457\n",
      "           1       0.99      1.00      0.99      1099\n",
      "\n",
      "    accuracy                           1.00      4556\n",
      "   macro avg       0.99      1.00      1.00      4556\n",
      "weighted avg       1.00      1.00      1.00      4556\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[3445   12]\n",
      " [   1 1098]]\n",
      "Accuracy: \n",
      " 0.9971466198419666\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training data set\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "pred = classifier.predict(xtrain)\n",
    "print(classification_report(ytrain, pred))\n",
    "print()\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(ytrain, pred))\n",
    "print(\"Accuracy: \\n\", accuracy_score(ytrain, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e576c3d1",
   "metadata": {},
   "source": [
    "It looks like the model used is 99.71% accurate. Let’s test the model on the test data set (xtest &  ytest) by printing the predicted value, and the actual value to see if the model can accurately classify the email text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbe3b0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ... 0 0 0]\n",
      "[1 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#print the predictions\n",
    "print(classifier.predict(xtest))\n",
    "#print the actual values\n",
    "print(ytest.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ead2a1",
   "metadata": {},
   "source": [
    "Now let’s evaluate the model on the test data set :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e26c29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       870\n",
      "           1       0.97      1.00      0.98       269\n",
      "\n",
      "    accuracy                           0.99      1139\n",
      "   macro avg       0.98      0.99      0.99      1139\n",
      "weighted avg       0.99      0.99      0.99      1139\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[862   8]\n",
      " [  1 268]]\n",
      "Accuracy: \n",
      " 0.9920983318700615\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training data set\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "pred = classifier.predict(xtest)\n",
    "print(classification_report(ytest, pred))\n",
    "print()\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(ytest, pred))\n",
    "print(\"Accuracy: \\n\", accuracy_score(ytest, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b031f36",
   "metadata": {},
   "source": [
    "The classifier accurately identified the email messages as spam or not spam with 99.2 % accuracy on the test data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
